
# This file was generated by the Tkinter Designer by Parth Jadhav
# https://github.com/ParthJadhav/Tkinter-Designer
import pyaudio
import wave
import time
import requests
import json
import assemblyai as aai
import keyboard
import openai
import pyttsx3
import threading
import pyglet

from pathlib import Path
from tkVideoPlayer import TkinterVideo
# from tkinter import *
# Explicit imports to satisfy Flake8
from tkinter import *
from tkinter import scrolledtext

pyglet.font.add_file("RussoOne-Regular.ttf")
stop_threads = False
recording1 = False
OUTPUT_PATH = Path(__file__).parent
ASSETS_PATH = OUTPUT_PATH / Path(r"D:\Legendary Programming Playground\Python Playground\Veronica Ai bot\assets")

# Constants for PyAudio
CHUNK = 1024
FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 16000
engine = pyttsx3.init()
voice = engine.getProperty('voices')
# engine.setProperty('voice', voice[0].id) #set the voice to index 0 for male voice
engine.setProperty('voice', voice[1].id)
recording = False
transcription = ""
filename = "temp.wav"


frames = []
output = ''
openai.api_key = "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"

window = Tk()
window.geometry("720x512")
window.configure(bg = "#000000")

canvas = Canvas(
    window,
    bg = "#000000",
    height = 600,
    width = 800,
    bd = 0,
    highlightthickness = 0,
    relief = "ridge",
)

canvas.place(x = 0, y = 0)

frame  = Frame(canvas,height = 300,width = 400)
frame.configure(bg = 'black')
frame.pack(expand = True,fill = 'both')
frame.place(x = -10,y=70,)
canvas.place()
window.resizable(False, False)
player = TkinterVideo(master = frame,scaled= False)
player.load(r"sample.mp4")
player.place( x = 0,y = 0, height=300,width = 400)
player.configure(bg = 'black')

def relative_to_assets(path: str) -> Path:
    return ASSETS_PATH / Path(path)

def playvid():
        player.play()

def stopvid():
    player.pause()
    
def loopvideo(event):
        player.play()

def run():
    while True:
        print('thread running')
        global stop_threads
        if stop_threads:
            break

        # Function to handle button press event for starting recording
def recorder():
    t1 = threading.Thread(target = record)
    global recording1
    if recording1 == False:
        recording1 = True
        t1.start()
    else:
         recording1 = False
         cleanup()
         stop_threads = True
         t1.join()
         stop_recording()


def record():
    textb.delete("0.0",END)
    global stream
    global audio
    audio = pyaudio.PyAudio() 
    stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)
    global recording1
    global frames
    frames = []
    playvid()
    print("Recording started.")
    while recording1:
        print("Bola Shet")
        data = stream.read(CHUNK)
        frames.append(data)       
    stop_recording()
# Function to handle button press event for stopping recording
def stop_recording():
    global frames
    global filename
    print("Recording stopped.")
    # Save the recorded audio as a WAV file
    wf = wave.open(filename, 'wb')
    wf.setnchannels(CHANNELS)
    wf.setsampwidth(audio.get_sample_size(FORMAT))
    wf.setframerate(RATE)
    wf.writeframes(b''.join(frames))
    wf.close()

    process_transcription(filename)



# def wrap_text(canvas, text, x, y, width, font):
#     words = text.split()
#     line = ""
#     i=0
#     for word in words:
#         i+=1
#         line = line + " " + word
#         if i4:
            
#             line = ""
#             y += 15
#             continue

    
         
    #lines = []
    #current_line = words[0]
    # for word in words:
    #     prin_words = ""
    #     if len(prin_words) != 4:
    #         len(prin_words)
    #         prin_words = prin_words + word
    #     else:
    #         current_line = prin_words
    #         lines.append(current_line)
    #         canvas.create_text(x, y, anchor='nw', text=current_line, font=font,fill="#00D1FF")
    #     y += 15
    # for line in lines:
    #     print(line)
    #     print(word)
    #     canvas.create_text(x, y, anchor='nw', text=line, font=font,fill="#00D1FF")
    #     y += 5
    #     continue




# Function to send transcription to OpenAI API and receive output
def process_transcription(filename):
    global lola
    global transcription
    global openai_api_key
    global output
    aai.settings.api_key = "90c53dc840e7456689bf3c847cc362bf"
    transcriber = aai.Transcriber()

    transcript = transcriber.transcribe(filename)
    transcription = transcript.text
    print(transcription)

    # Send prompt to OpenAI API
    response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
            {"role": "system", "content": "You are a intelligent Ai bot named Veronica"},
            {"role": "user", "content": transcription},
        ]
    )

    output = response['choices'][0]['message']['content']
    print(output)
    output1 = "User: "+ transcription + "\n\nVeronica: " + output + "\n\n\n"
    textb.insert(END, output1)
    # canvas.create_text(449, 165,width = 172, anchor='nw', text=output, font=("RussoOne-Regular",15 * -1),fill="#00D1FF")
    engine.say(output)
    engine.runAndWait()


    # Cleanup
def cleanup():
    stream.stop_stream()
    stream.close()
    audio.terminate()

def main():
   
    player.bind('<<Ended>>',loopvideo)
    window.mainloop()

button_image_1 = PhotoImage(
    file=relative_to_assets("button_1.png"))
button_1 = Button(
    image=button_image_1,
    borderwidth=0,
    highlightthickness=0,
    command=recorder,
    relief="flat"
)
button_1.place(
    x=160.73712158203125,
    y=400.88702392578125,
    width=56.11297607421875,
    height=56.11298370361328
)

# button_image_2 = PhotoImage(
#     file=relative_to_assets("button_2.png"))
# button_2 = Button(
#     image=button_image_2,
#     borderwidth=0,
#     highlightthickness=0,
#     command=stop_recording,
#     relief="flat"
# )
# button_2.place(
#     x=200.2532958984375,
#     y=382.0325012207031,
#     width=55.82220458984375,
#     height=55.82221984863281
# )

canvas.create_text(
    400.0,
    109.0,
    anchor="nw",
    text="Output:",
    fill="#00D1FF",
    font=("Russo One", 32 * -1)
)

canvas.create_text(
    227.0,
    9.0,
    anchor="nw",
    text="VERONICA",
    fill="#00D1FF",
    font=("Russo One", 48 * -1)
)

textb = Text(window, height=15,width=30,font=("Russo One", 15 * -1),bg="black",fg="#00D1FF",relief=FLAT, wrap = WORD)
textb.place(x=369,y=165)



# while True:
#     # Simulate button press events
#     button_1.is_pressed() = True  # Replace with actual button press detection
#     button_stop_pressed = False  # Replace with actual button press detection
#     if keyboard.is_pressed("0"):
#         button_stop_pressed = True 
#         button_start_pressed = False
#         stop_recording()
#         cleanup()
#         break
#     if button_start_pressed:
#         start_recording()
#     elif button_stop_pressed:
#         stop_recording()
#         cleanup()
#         break
        # Adjust the sleep duration as per your requirement

if __name__ == "__main__":
    playvid()
    main()